import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
import os
from google.cloud import bigquery
from prophet import Prophet
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score, mean_absolute_error, mean_squared_error, r2_score
import numpy as np
from scipy.interpolate import make_interp_spline

# Thi·∫øt l·∫≠p x√°c th·ª±c Google BigQuery
os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = "D:/C√Å NH√ÇN/terminal/terminal/etl-cap3-27b899b6d343.json"
client = bigquery.Client(project='etl-cap3')

# Thi·∫øt l·∫≠p ti√™u ƒë·ªÅ v√† m√¥ t·∫£
st.title("·ª®ng D·ª•ng Ph√¢n T√≠ch Doanh Thu v√† Ph√¢n C·ª•m Kh√°ch H√†ng")
st.markdown("""
·ª®ng d·ª•ng n√†y hi·ªÉn th·ªã ph√¢n c·ª•m kh√°ch h√†ng, d·ª± ƒëo√°n doanh thu, v√† c√°c bi·ªÉu ƒë·ªì ph√¢n t√≠ch d·ª±a tr√™n d·ªØ li·ªáu t·ª´ Google BigQuery.
Vui l√≤ng ch·ªçn tab ƒë·ªÉ xem c√°c ph√¢n t√≠ch chi ti·∫øt.
""")

# T·∫£i d·ªØ li·ªáu t·ª´ BigQuery
@st.cache_data
def load_data():
    query = """
        SELECT * FROM etl-cap3.Sale_AMZ_ETSY.FinalData
        LIMIT 500000000
    """
    df = client.query(query).to_dataframe()
    df['Order Date'] = pd.to_datetime(df['Order Date'])
    df['year'] = df['Order Date'].dt.year
    return df

# T·∫£i d·ªØ li·ªáu
with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu t·ª´ BigQuery..."):
    df = load_data()

# T·∫°o c√°c tab
tab1, tab2, tab3, tab4 = st.tabs(["T·ªïng Quan Doanh Thu", "D·ª± ƒêo√°n Doanh Thu", "Ph√¢n C·ª•m Kh√°ch H√†ng", "ƒê√°nh Gi√° M√¥ H√¨nh"])

# Tab 1: T·ªïng Quan Doanh Thu
with tab1:
    st.header("T·ªïng Quan Doanh Thu Theo NƒÉm")
    revenue_by_year = df.groupby('year')['Order Total'].sum().reset_index()

    # V·∫Ω bi·ªÉu ƒë·ªì doanh thu theo nƒÉm v·ªõi Plotly
    fig = px.bar(revenue_by_year, x='year', y='Order Total', title='T·ªïng Doanh Thu Theo NƒÉm',
                 labels={'year': 'NƒÉm', 'Order Total': 'T·ªïng Doanh Thu'}, color_discrete_sequence=['red'])
    fig.update_layout(xaxis_tickangle=0, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig)

# Tab 2: D·ª± ƒêo√°n Doanh Thu
with tab2:
    st.header("D·ª± ƒêo√°n Doanh Thu v·ªõi Prophet")

    # Chu·∫©n b·ªã d·ªØ li·ªáu cho Prophet
    prophet_df = df[['Order Date', 'Order Total']].rename(columns={'Order Date': 'ds', 'Order Total': 'y'})
    prophet_df = prophet_df.groupby('ds').sum().reset_index()

    # L√†m m∆∞·ª£t d·ªØ li·ªáu th·ª±c t·∫ø
    prophet_df['y_smooth'] = prophet_df['y'].rolling(window=5, center=True, min_periods=1).mean()
    prophet_df['ds_numeric'] = prophet_df['ds'].apply(lambda x: x.timestamp())
    prophet_df = prophet_df.sort_values('ds_numeric')

    # N·ªôi suy ƒë·ªÉ l√†m m∆∞·ª£t
    x = prophet_df['ds_numeric']
    y = prophet_df['y_smooth']
    x_smooth = np.linspace(x.min(), x.max(), 500)
    spl = make_interp_spline(x, y, k=3)
    y_smooth = spl(x_smooth)
    ds_smooth = pd.to_datetime(x_smooth, unit='s')

    # Hu·∫•n luy·ªán m√¥ h√¨nh Prophet
    model = Prophet(yearly_seasonality=True, weekly_seasonality=True, daily_seasonality=True, changepoint_prior_scale=0.01)
    model.fit(prophet_df)

    # Bi·ªÉu ƒë·ªì 1: Th·ª±c t·∫ø v√† d·ª± ƒëo√°n trong ph·∫°m vi d·ªØ li·ªáu g·ªëc
    past_future = prophet_df[['ds']].copy()
    past_forecast = model.predict(past_future)
    past_forecast['yhat_smooth'] = past_forecast['yhat'].rolling(window=5, center=True, min_periods=1).mean()
    past_forecast['yhat_lower_smooth'] = past_forecast['yhat_lower'].rolling(window=5, center=True, min_periods=1).mean()
    past_forecast['yhat_upper_smooth'] = past_forecast['yhat_upper'].rolling(window=5, center=True, min_periods=1).mean()

    # V·∫Ω bi·ªÉu ƒë·ªì v·ªõi Plotly
    fig1 = go.Figure()
    fig1.add_trace(go.Scatter(x=ds_smooth, y=y_smooth, mode='lines', name='Th·ª±c t·∫ø', line=dict(color='blue', width=1)))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_smooth'], mode='lines', name='D·ª± ƒëo√°n', line=dict(color='orange', width=1)))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_upper_smooth'], mode='lines', name='Kho·∫£ng tin c·∫≠y (tr√™n)', line=dict(color='yellow', width=0), showlegend=False))
    fig1.add_trace(go.Scatter(x=past_forecast['ds'], y=past_forecast['yhat_lower_smooth'], mode='lines', name='Kho·∫£ng tin c·∫≠y (d∆∞·ªõi)', line=dict(color='yellow', width=0), fill='tonexty', fillcolor='rgba(255, 255, 0, 0.2)'))
    fig1.update_layout(title='Gi√° tr·ªã b√°n h√†ng h√†ng th√°ng - Prophet (T·∫≠p g·ªëc)', xaxis_title='Ng√†y', yaxis_title='Gi√° tr·ªã b√°n h√†ng', xaxis_tickformat='%Y-%m', xaxis_tickangle=45, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig1)

    # Bi·ªÉu ƒë·ªì 2: D·ª± ƒëo√°n 12 th√°ng ti·∫øp theo
    future = model.make_future_dataframe(periods=365, freq='D')
    future_forecast = model.predict(future)
    future_forecast['yhat_smooth'] = future_forecast['yhat'].rolling(window=5, center=True, min_periods=1).mean()
    future_forecast['yhat_lower_smooth'] = future_forecast['yhat_lower'].rolling(window=5, center=True, min_periods=1).mean()
    future_forecast['yhat_upper_smooth'] = future_forecast['yhat_upper'].rolling(window=5, center=True, min_periods=1).mean()

    # V·∫Ω bi·ªÉu ƒë·ªì d·ª± ƒëo√°n t∆∞∆°ng lai
    fig2 = go.Figure()
    fig2.add_trace(go.Scatter(x=ds_smooth, y=y_smooth, mode='lines', name='Th·ª±c t·∫ø', line=dict(color='blue', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='D·ª± ƒëo√°n', line=dict(color='orange', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='D·ª± ƒëo√°n t∆∞∆°ng lai', line=dict(color='red', width=1)))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_upper_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y (tr√™n)', line=dict(color='yellow', width=0), showlegend=False))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              y=future_forecast['yhat_lower_smooth'][future_forecast['ds'] <= prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y (d∆∞·ªõi)', line=dict(color='yellow', width=0), fill='tonexty', fillcolor='rgba(255, 255, 0, 0.2)'))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_upper_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y t∆∞∆°ng lai (tr√™n)', line=dict(color='pink', width=0), showlegend=False))
    fig2.add_trace(go.Scatter(x=future_forecast['ds'][future_forecast['ds'] > prophet_df['ds'].max()],
                              y=future_forecast['yhat_lower_smooth'][future_forecast['ds'] > prophet_df['ds'].max()],
                              mode='lines', name='Kho·∫£ng tin c·∫≠y t∆∞∆°ng lai (d∆∞·ªõi)', line=dict(color='pink', width=0), fill='tonexty', fillcolor='rgba(255, 192, 203, 0.2)'))
    fig2.update_layout(title='D·ª± ƒëo√°n gi√° tr·ªã b√°n h√†ng 12 th√°ng ti·∫øp theo - Prophet', xaxis_title='Ng√†y', yaxis_title='Gi√° tr·ªã b√°n h√†ng', xaxis_tickformat='%Y-%m', xaxis_tickangle=45, yaxis=dict(griddash='dash', gridcolor='gray'))
    st.plotly_chart(fig2)

    # Hi·ªÉn th·ªã c√°c ch·ªâ s·ªë ƒë√°nh gi√°
    eval_df = pd.merge(prophet_df[['ds', 'y']], past_forecast[['ds', 'yhat']], on='ds')
    mae = mean_absolute_error(eval_df['y'], eval_df['yhat'])
    rmse = np.sqrt(mean_squared_error(eval_df['y'], eval_df['yhat']))
    mape = np.mean(np.abs((eval_df['y'] - eval_df['yhat']) / eval_df['y'])) * 100
    r2 = r2_score(eval_df['y'], eval_df['yhat'])

    st.subheader("ƒê√°nh Gi√° M√¥ H√¨nh D·ª± ƒêo√°n")
    st.write(f"üìä MAE: {mae:.2f}")
    st.write(f"üìä RMSE: {rmse:.2f}")
    st.write(f"üìä MAPE: {mape:.2f}%")
    st.write(f"üìä R¬≤ Score: {r2:.2f}")

# Tab 3: Ph√¢n C·ª•m Kh√°ch H√†ng
with tab3:
    st.header("Ph√¢n C·ª•m Kh√°ch H√†ng v·ªõi GMM")

    # L·∫•y m·∫´u d·ªØ li·ªáu
    df_sample = df.sample(n=35000, random_state=42)
    df_cluster = df_sample[['Product Cost', 'Shipping Fee', 'Order Total', 'Profit']]

    # Chu·∫©n h√≥a v√† PCA
    scaler = StandardScaler()
    df_scaled = scaler.fit_transform(df_cluster)
    pca = PCA(n_components=2)
    df_pca = pca.fit_transform(df_scaled)

    # Ph√¢n c·ª•m v·ªõi GMM
    gmm = GaussianMixture(n_components=7, random_state=42)
    clusters = gmm.fit_predict(df_pca)
    df_sample['Cluster'] = clusters

    # V·∫Ω bi·ªÉu ƒë·ªì ph√¢n c·ª•m
    fig3 = px.scatter(x=df_pca[:, 0], y=df_pca[:, 1], color=clusters.astype(str), title='Ph√¢n C·ª•m Kh√°ch H√†ng v·ªõi GMM',
                      labels={'x': 'PCA 1', 'y': 'PCA 2', 'color': 'Cluster'}, color_discrete_sequence=px.colors.qualitative.T10)
    fig3.update_layout(showlegend=True)
    st.plotly_chart(fig3)

    # Hi·ªÉn th·ªã k·∫øt qu·∫£ ph√¢n c·ª•m
    st.subheader("K·∫øt Qu·∫£ Ph√¢n C·ª•m (M·∫´u)")
    st.dataframe(df_sample[['Order Id', 'City', 'Country', 'Cluster']].head())

    # Ph√¢n t√≠ch ƒë·∫∑c tr∆∞ng t·ª´ng c·ª•m
    df_analysis = df_sample[['Product Cost', 'Shipping Fee', 'Order Total', 'Profit', 'Cluster']].copy()
    cluster_summary = df_analysis.groupby('Cluster').mean().round(2)
    cluster_counts = df_analysis['Cluster'].value_counts().sort_index()
    cluster_summary['Count'] = cluster_counts

    st.subheader("ƒê·∫∑c Tr∆∞ng Trung B√¨nh c·ªßa T·ª´ng C·ª•m")
    st.dataframe(cluster_summary)

# Tab 4: ƒê√°nh Gi√° M√¥ H√¨nh Ph√¢n C·ª•m
with tab4:
    st.header("ƒê√°nh Gi√° M√¥ H√¨nh Ph√¢n C·ª•m")

    # ƒê√°nh gi√° ph√¢n c·ª•m
    df_valid = df_sample.dropna(subset=['Cluster'])
    X_valid = df_pca
    labels = df_valid['Cluster']

    sil_score = silhouette_score(X_valid, labels)
    db_index = davies_bouldin_score(X_valid, labels)
    ch_index = calinski_harabasz_score(X_valid, labels)

    st.write(f"üìä Silhouette Score: {sil_score:.3f}")
    st.write(f"üìä Davies-Bouldin Index: {db_index:.3f}")
    st.write(f"üìä Calinski-Harabasz Index: {ch_index:.3f}")
    st.write(f"üìä S·ªë c·ª•m: {len(set(labels))}")

# Footer
st.markdown("---")
st.markdown("·ª®ng d·ª•ng ƒë∆∞·ª£c x√¢y d·ª±ng v·ªõi Streamlit b·ªüi xAI. Li√™n h·ªá h·ªó tr·ª£: support@x.ai")